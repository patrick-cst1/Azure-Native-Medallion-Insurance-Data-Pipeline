name: Deploy Azure-Native Medallion Pipeline

on:
  push:
    branches:
      - main
      - master
  workflow_dispatch:

env:
  AZURE_RESOURCE_GROUP: rg-insurance-ml-pipeline
  AZURE_LOCATION: eastasia
  ENVIRONMENT: dev
  BASE_NAME: insml

jobs:
  deploy-infrastructure:
    runs-on: ubuntu-latest
    outputs:
      storageAccountName: ${{ steps.deploy.outputs.storageAccountName }}
      synapseWorkspaceName: ${{ steps.deploy.outputs.synapseWorkspaceName }}
      sparkPoolName: ${{ steps.deploy.outputs.sparkPoolName }}
      filesContainerName: ${{ steps.deploy.outputs.filesContainerName }}
      tablesContainerName: ${{ steps.deploy.outputs.tablesContainerName }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Create Resource Group
        run: |
          az group create \
            --name ${{ env.AZURE_RESOURCE_GROUP }} \
            --location ${{ env.AZURE_LOCATION }}

      - name: Register Required Resource Providers
        run: |
          echo "Registering Azure Resource Providers..."
          
          # Register providers with explicit wait
          for provider in Microsoft.Storage Microsoft.Synapse Microsoft.KeyVault Microsoft.Network Microsoft.Sql; do
            echo "Registering $provider..."
            az provider register --namespace $provider
          done
          
          # Wait for all providers to be registered (max 10 minutes)
          echo "Waiting for providers to be registered..."
          for i in {1..60}; do
            STORAGE=$(az provider show --namespace Microsoft.Storage --query "registrationState" -o tsv)
            SYNAPSE=$(az provider show --namespace Microsoft.Synapse --query "registrationState" -o tsv)
            KEYVAULT=$(az provider show --namespace Microsoft.KeyVault --query "registrationState" -o tsv)
            NETWORK=$(az provider show --namespace Microsoft.Network --query "registrationState" -o tsv)
            SQL=$(az provider show --namespace Microsoft.Sql --query "registrationState" -o tsv)
            
            if [ "$STORAGE" = "Registered" ] && [ "$SYNAPSE" = "Registered" ] && [ "$KEYVAULT" = "Registered" ] && [ "$NETWORK" = "Registered" ] && [ "$SQL" = "Registered" ]; then
              echo "âœ… All providers registered successfully"
              break
            fi
            
            echo "Attempt $i/60: Storage=$STORAGE, Synapse=$SYNAPSE, KeyVault=$KEYVAULT, Network=$NETWORK, Sql=$SQL"
            sleep 10
          done
          
          # Final verification
          echo "Final verification:"
          az provider show --namespace Microsoft.Storage --query "registrationState"
          az provider show --namespace Microsoft.Synapse --query "registrationState"
          az provider show --namespace Microsoft.KeyVault --query "registrationState"
          az provider show --namespace Microsoft.Network --query "registrationState"
          az provider show --namespace Microsoft.Sql --query "registrationState"

      - name: Deploy Bicep Infrastructure
        id: deploy
        uses: azure/cli@v2
        with:
          azcliversion: latest
          inlineScript: |
            set -e
            DEPLOYMENT_NAME="main-$(date +%s)"
            
            echo "Validating Bicep template..."
            az deployment group validate \
              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
              --template-file ./infrastructure/main.bicep \
              --parameters baseName=${{ env.BASE_NAME }} environmentName=${{ env.ENVIRONMENT }} location=${{ env.AZURE_LOCATION }}
            
            echo "Deploying Bicep template..."
            set +e
            az deployment group create \
              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
              --name "$DEPLOYMENT_NAME" \
              --template-file ./infrastructure/main.bicep \
              --parameters baseName=${{ env.BASE_NAME }} environmentName=${{ env.ENVIRONMENT }} location=${{ env.AZURE_LOCATION }}
            EXIT_CODE=$?
            set -e

            if [ $EXIT_CODE -ne 0 ]; then
              echo "Deployment failed. Fetching detailed operations..."
              echo "==== Deployment Summary ===="
              az deployment group show \
                --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
                --name "$DEPLOYMENT_NAME" -o jsonc || true

              echo "==== All Operations ===="
              az deployment operation group list \
                --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
                --name "$DEPLOYMENT_NAME" -o jsonc || true

              echo "==== Failed Operations Only ===="
              az deployment operation group list \
                --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
                --name "$DEPLOYMENT_NAME" \
                --query "[?properties.provisioningState=='Failed']" -o jsonc || true

              exit $EXIT_CODE
            fi
            
            echo "storageAccountName=$(az deployment group show --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name "$DEPLOYMENT_NAME" --query "properties.outputs.storageAccountName.value" -o tsv)" >> $GITHUB_OUTPUT
            echo "synapseWorkspaceName=$(az deployment group show --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name "$DEPLOYMENT_NAME" --query "properties.outputs.synapseWorkspaceName.value" -o tsv)" >> $GITHUB_OUTPUT
            echo "sparkPoolName=$(az deployment group show --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name "$DEPLOYMENT_NAME" --query "properties.outputs.sparkPoolName.value" -o tsv)" >> $GITHUB_OUTPUT
            echo "filesContainerName=$(az deployment group show --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name "$DEPLOYMENT_NAME" --query "properties.outputs.filesContainerName.value" -o tsv)" >> $GITHUB_OUTPUT
            echo "tablesContainerName=$(az deployment group show --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name "$DEPLOYMENT_NAME" --query "properties.outputs.tablesContainerName.value" -o tsv)" >> $GITHUB_OUTPUT

      - name: Display Infrastructure Outputs
        run: |
          echo "Storage Account: ${{ steps.deploy.outputs.storageAccountName }}"
          echo "Synapse Workspace: ${{ steps.deploy.outputs.synapseWorkspaceName }}"
          echo "Spark Pool: ${{ steps.deploy.outputs.sparkPoolName }}"

  upload-data-and-schemas:
    runs-on: ubuntu-latest
    needs: deploy-infrastructure
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install Azure CLI extensions
        run: |
          set -e
          az extension add -n storage-blob-preview --allow-preview || az extension update -n storage-blob-preview || true
          az config set extension.use_dynamic_install=yes_without_prompt

          if ! az extension show -n synapse >/dev/null 2>&1; then
            echo "Attempting to install Synapse CLI extension..."
            if az extension add -n synapse --allow-preview; then
              echo "Synapse extension installed from official index."
            else
              echo "Warning: Synapse extension not found in official index. Falling back to dynamic installation."
            fi
          else
            az extension update -n synapse || true
          fi

      - name: Upload sample data to ADLS
        run: |
          echo "Uploading sample CSV files..."
          az storage fs directory upload \
            --account-name ${{ needs.deploy-infrastructure.outputs.storageAccountName }} \
            --file-system ${{ needs.deploy-infrastructure.outputs.filesContainerName }} \
            --auth-mode login \
            --source ./data/samples \
            --destination samples \
            --recursive

      - name: Upload schema files to ADLS
        run: |
          echo "Uploading YAML schema files..."
          az storage fs directory upload \
            --account-name ${{ needs.deploy-infrastructure.outputs.storageAccountName }} \
            --file-system ${{ needs.deploy-infrastructure.outputs.filesContainerName }} \
            --auth-mode login \
            --source ./config/schemas \
            --destination config/schemas \
            --recursive

  deploy-synapse-artifacts:
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure, upload-data-and-schemas]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install Azure CLI extensions (synapse)
        run: |
          set -e
          az config set extension.use_dynamic_install=yes_without_prompt
          if ! az extension show -n synapse >/dev/null 2>&1; then
            echo "Attempting to install Synapse CLI extension..."
            if az extension add -n synapse --allow-preview; then
              echo "Synapse extension installed from official index."
            else
              echo "Warning: Synapse extension not found in official index. Falling back to dynamic installation."
            fi
          else
            az extension update -n synapse || true
          fi

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Update Notebook Storage Account Configuration
        run: |
          echo "Updating notebooks with storage account name..."
          python scripts/update_notebook_config.py ${{ needs.deploy-infrastructure.outputs.storageAccountName }}

      - name: Import Synapse Notebooks
        run: |
          WORKSPACE=${{ needs.deploy-infrastructure.outputs.synapseWorkspaceName }}
          
          echo "Importing Bronze notebooks..."
          az synapse notebook import --workspace-name $WORKSPACE --name bronze_ingest_policies --file @synapse/notebooks/bronze_ingest_policies.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          az synapse notebook import --workspace-name $WORKSPACE --name bronze_ingest_claims --file @synapse/notebooks/bronze_ingest_claims.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          az synapse notebook import --workspace-name $WORKSPACE --name bronze_ingest_customers --file @synapse/notebooks/bronze_ingest_customers.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          az synapse notebook import --workspace-name $WORKSPACE --name bronze_ingest_agents --file @synapse/notebooks/bronze_ingest_agents.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          
          echo "Importing Silver notebooks..."
          az synapse notebook import --workspace-name $WORKSPACE --name silver_clean_policies --file @synapse/notebooks/silver_clean_policies.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          az synapse notebook import --workspace-name $WORKSPACE --name silver_clean_claims --file @synapse/notebooks/silver_clean_claims.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          az synapse notebook import --workspace-name $WORKSPACE --name silver_clean_customers --file @synapse/notebooks/silver_clean_customers.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          az synapse notebook import --workspace-name $WORKSPACE --name silver_clean_agents --file @synapse/notebooks/silver_clean_agents.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          
          echo "Importing Gold notebooks..."
          az synapse notebook import --workspace-name $WORKSPACE --name gold_create_claims_features --file @synapse/notebooks/gold_create_claims_features.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          az synapse notebook import --workspace-name $WORKSPACE --name gold_create_customer_features --file @synapse/notebooks/gold_create_customer_features.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          az synapse notebook import --workspace-name $WORKSPACE --name gold_create_risk_features --file @synapse/notebooks/gold_create_risk_features.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true
          az synapse notebook import --workspace-name $WORKSPACE --name gold_create_monthly_claims_summary --file @synapse/notebooks/gold_create_monthly_claims_summary.ipynb --spark-pool-name ${{ needs.deploy-infrastructure.outputs.sparkPoolName }} || true

      - name: Create Synapse Pipeline
        run: |
          WORKSPACE=${{ needs.deploy-infrastructure.outputs.synapseWorkspaceName }}
          
          echo "Creating master batch pipeline..."
          az synapse pipeline create \
            --workspace-name $WORKSPACE \
            --name master_batch_pipeline \
            --file @synapse/pipelines/master_batch_pipeline.json || true

      - name: Create and Start Daily Trigger
        run: |
          WORKSPACE=${{ needs.deploy-infrastructure.outputs.synapseWorkspaceName }}
          TRIGGER_FILE="synapse/pipelines/triggers/daily_trigger.json"
          
          if [ ! -f "$TRIGGER_FILE" ]; then
            echo "Error: Trigger file not found at $TRIGGER_FILE"
            exit 1
          fi
          
          echo "Creating daily trigger..."
          az synapse trigger create \
            --workspace-name $WORKSPACE \
            --name DailySchedule \
            --file @"$TRIGGER_FILE" || true
          
          echo "Starting daily trigger..."
          az synapse trigger start \
            --workspace-name $WORKSPACE \
            --name DailySchedule || true

  post-deployment:
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure, upload-data-and-schemas, deploy-synapse-artifacts]
    
    steps:
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Display Deployment Summary
        run: |
          echo "=========================================="
          echo "âœ… Deployment Completed Successfully!"
          echo "=========================================="
          echo ""
          echo "ðŸ“¦ Resources Created:"
          echo "  - Synapse Workspace: ${{ needs.deploy-infrastructure.outputs.synapseWorkspaceName }}"
          echo "  - Storage Account: ${{ needs.deploy-infrastructure.outputs.storageAccountName }}"
          echo "  - Spark Pool: ${{ needs.deploy-infrastructure.outputs.sparkPoolName }}"
          echo ""
          echo "ðŸ“Š Data Uploaded:"
          echo "  - Sample CSVs: abfss://${{ needs.deploy-infrastructure.outputs.filesContainerName }}@${{ needs.deploy-infrastructure.outputs.storageAccountName }}.dfs.core.windows.net/samples/"
          echo "  - YAML Schemas: abfss://${{ needs.deploy-infrastructure.outputs.filesContainerName }}@${{ needs.deploy-infrastructure.outputs.storageAccountName }}.dfs.core.windows.net/config/schemas/"
          echo ""
          echo "ðŸš€ Next Steps:"
          echo "  1. Navigate to Azure Portal â†’ Synapse Workspace"
          echo "  2. Run 'master_batch_pipeline' manually or wait for daily trigger (2:00 UTC)"
          echo "  3. Verify Delta tables in ADLS: bronze_*, silver_*, gold_*"
          echo ""
          echo "ðŸ’° Cost Management:"
          echo "  - Spark Pool auto-pauses after 15 minutes of inactivity"
          echo "  - To delete all resources: az group delete --name ${{ env.AZURE_RESOURCE_GROUP }}"
