{
	"name": "gold_create_claims_features",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "insmlsparkdev",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false
		},
		"metadata": {
			"language_info": {
				"name": "python"
			}
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"# Gold Layer: Create ML-Ready Claims Features\n",
					"Azure Synapse Analytics - Medallion Architecture\n",
					"\n",
					"Pattern: Aggregated features for ML workflows"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.functions import col, count, sum as spark_sum, avg, max as spark_max, current_timestamp\n",
					"import logging"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Configuration - ADLS Gen2 paths\n",
					"STORAGE_ACCOUNT = \"insmlstdevyx4ce6\"\n",
					"TABLES_ROOT = f\"abfss://tables@{STORAGE_ACCOUNT}.dfs.core.windows.net\"\n",
					"\n",
					"SILVER_CLAIMS_PATH = f\"{TABLES_ROOT}/silver/silver_claims\"\n",
					"GOLD_FEATURES_PATH = f\"{TABLES_ROOT}/gold/gold_claims_features\"\n",
					"\n",
					"logging.basicConfig(level=logging.INFO)\n",
					"logger = logging.getLogger(__name__)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"def main():\n",
					"    spark = SparkSession.builder.getOrCreate()\n",
					"\n",
					"    try:\n",
					"        logger.info(f\"Reading from {SILVER_CLAIMS_PATH}\")\n",
					"        df_claims = spark.read.format(\"delta\").load(SILVER_CLAIMS_PATH)\n",
					"\n",
					"        record_count = df_claims.count()\n",
					"        logger.info(f\"Read {record_count} claims from Silver\")\n",
					"\n",
					"        # Simple aggregation features by customer\n",
					"        claims_features = df_claims.groupBy(\"customer_id\").agg(\n",
					"            count(\"claim_id\").alias(\"total_claims\"),\n",
					"            spark_sum(\"claim_amount\").alias(\"total_claim_amount\"),\n",
					"            avg(\"claim_amount\").alias(\"avg_claim_amount\"),\n",
					"            spark_max(\"claim_amount\").alias(\"max_claim_amount\")\n",
					"        )\n",
					"\n",
					"        # Add feature timestamp\n",
					"        claims_features = claims_features.withColumn(\"feature_timestamp\", current_timestamp())\n",
					"\n",
					"        feature_count = claims_features.count()\n",
					"        logger.info(f\"Created features for {feature_count} customers\")\n",
					"\n",
					"        # Write to Gold\n",
					"        logger.info(f\"Writing to {GOLD_FEATURES_PATH}\")\n",
					"        claims_features.write \\\n",
					"            .format(\"delta\") \\\n",
					"            .mode(\"overwrite\") \\\n",
					"            .option(\"description\", \"Gold layer: Aggregated claims features for ML\") \\\n",
					"            .save(GOLD_FEATURES_PATH)\n",
					"\n",
					"        logger.info(\"✓ Claims features creation completed\")\n",
					"\n",
					"    except Exception as e:\n",
					"        logger.error(f\"✗ Failed to create claims features: {str(e)}\")\n",
					"        raise"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"main()"
				]
			}
		]
	}
}